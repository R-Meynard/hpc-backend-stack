#include <iostream>
#include <vector>
#include <string>
#include <iomanip>

class GPUResource {
private:
    std::string name;
    int memoryGB;
    bool isAvailable;
    
public:
    // Constructeur
    GPUResource(std::string gpuName, int memory) 
        : name(gpuName), memoryGB(memory), isAvailable(true) {
        // Par d√©faut, un GPU est disponible √† la cr√©ation
    }
    
    // Getters
    bool getAvailability() const {
        return isAvailable;
    }
    
    std::string getName() const {
        return name;
    }
    
    int getMemory() const {
        return memoryGB;
    }
    
    // Setter pour la disponibilit√©
    void setAvailability(bool available) {
        isAvailable = available;
    }
    
    // Affichage des informations du GPU
    void displayInfo() const {
        std::cout << "GPU: " << std::setw(15) << std::left << name 
                  << " | M√©moire: " << std::setw(3) << memoryGB << " GB"
                  << " | √âtat: " << (isAvailable ? "Disponible" : "Occup√©") << std::endl;
    }
};

// Fonction utilitaire pour afficher un s√©parateur
void printSeparator() {
    std::cout << std::string(50, '-') << std::endl;
}

// Fonction pour compter les GPUs disponibles
int countAvailableGPUs(const std::vector<GPUResource>& cluster) {
    int count = 0;
    for (const auto& gpu : cluster) {
        if (gpu.getAvailability()) {
            count++;
        }
    }
    return count;
}

// Fonction pour afficher le statut du cluster
void displayClusterStatus(const std::vector<GPUResource>& cluster) {
    std::cout << "\n=== √âTAT DU CLUSTER GPU ===" << std::endl;
    printSeparator();
    
    for (size_t i = 0; i < cluster.size(); ++i) {
        std::cout << "GPU " << (i + 1) << " - ";
        cluster[i].displayInfo();
    }
    
    printSeparator();
    int available = countAvailableGPUs(cluster);
    int total = cluster.size();
    std::cout << "R√©sum√©: " << available << "/" << total << " GPUs disponibles" << std::endl;
    
    // Calcul de la m√©moire totale disponible
    int totalAvailableMemory = 0;
    for (const auto& gpu : cluster) {
        if (gpu.getAvailability()) {
            totalAvailableMemory += gpu.getMemory();
        }
    }
    std::cout << "M√©moire disponible totale: " << totalAvailableMemory << " GB" << std::endl;
}

// Fonction pour trouver un GPU disponible avec suffisamment de m√©moire
int findAvailableGPU(const std::vector<GPUResource>& cluster, int minMemoryGB) {
    for (size_t i = 0; i < cluster.size(); ++i) {
        if (cluster[i].getAvailability() && cluster[i].getMemory() >= minMemoryGB) {
            return static_cast<int>(i);
        }
    }
    return -1; // Aucun GPU disponible trouv√©
}

int main() {
    std::cout << "=== SYST√àME DE GESTION GPU FLEXAI ===" << std::endl;
    
    // Cr√©er un vecteur de GPUs (cluster)
    std::vector<GPUResource> gpuCluster;
    
    // Ajouter 3 GPUs diff√©rents avec leurs sp√©cifications r√©elles
    gpuCluster.emplace_back("NVIDIA A100", 40);   // GPU haut de gamme pour l'IA
    gpuCluster.emplace_back("NVIDIA H100", 80);   // Derni√®re g√©n√©ration NVIDIA
    gpuCluster.emplace_back("AMD MI250", 128);    // GPU AMD pour calcul intensif
    
    // Afficher l'√©tat initial du cluster
    std::cout << "\nüöÄ Initialisation du cluster..." << std::endl;
    displayClusterStatus(gpuCluster);
    
    // Simulation d'allocation de ressources
    std::cout << "\nüìã SIMULATION D'ALLOCATION DE RESSOURCES" << std::endl;
    printSeparator();
    
    // Sc√©nario 1: Lancer un job d'entra√Ænement qui n√©cessite 60GB
    std::cout << "üîç Recherche d'un GPU avec au moins 60GB pour un job d'entra√Ænement..." << std::endl;
    int gpuIndex = findAvailableGPU(gpuCluster, 60);
    
    if (gpuIndex != -1) {
        std::cout << "‚úÖ GPU trouv√©: " << gpuCluster[gpuIndex].getName() 
                  << " (Index: " << gpuIndex << ")" << std::endl;
        gpuCluster[gpuIndex].setAvailability(false);
        std::cout << "üîí GPU allou√© pour le job d'entra√Ænement" << std::endl;
    } else {
        std::cout << "‚ùå Aucun GPU disponible avec suffisamment de m√©moire" << std::endl;
    }
    
    // Sc√©nario 2: Marquer le premier GPU comme occup√©
    std::cout << "\nüîí Allocation du premier GPU pour un job d'inf√©rence..." << std::endl;
    if (gpuCluster[0].getAvailability()) {
        gpuCluster[0].setAvailability(false);
        std::cout << "‚úÖ " << gpuCluster[0].getName() << " allou√©" << std::endl;
    } else {
        std::cout << "‚ö†Ô∏è  " << gpuCluster[0].getName() << " d√©j√† occup√©" << std::endl;
    }
    
    // Afficher l'√©tat apr√®s allocations
    displayClusterStatus(gpuCluster);
    
    // Sc√©nario 3: Lib√©ration d'un GPU
    std::cout << "\nüîì LIB√âRATION DE RESSOURCES" << std::endl;
    printSeparator();
    std::cout << "Job d'entra√Ænement termin√©, lib√©ration du GPU..." << std::endl;
    
    if (gpuIndex != -1) {
        gpuCluster[gpuIndex].setAvailability(true);
        std::cout << "‚úÖ " << gpuCluster[gpuIndex].getName() << " lib√©r√©" << std::endl;
    }
    
    // √âtat final
    displayClusterStatus(gpuCluster);
    
    // Statistiques finales
    std::cout << "\nüìä STATISTIQUES FINALES" << std::endl;
    printSeparator();
    
    int totalMemory = 0;
    int availableMemory = 0;
    int occupiedGPUs = 0;
    
    for (const auto& gpu : gpuCluster) {
        totalMemory += gpu.getMemory();
        if (gpu.getAvailability()) {
            availableMemory += gpu.getMemory();
        } else {
            occupiedGPUs++;
        }
    }
    
    double utilizationRate = (double)occupiedGPUs / gpuCluster.size() * 100;
    
    std::cout << "Nombre total de GPUs: " << gpuCluster.size() << std::endl;
    std::cout << "GPUs occup√©s: " << occupiedGPUs << std::endl;
    std::cout << "Taux d'utilisation: " << std::fixed << std::setprecision(1) 
              << utilizationRate << "%" << std::endl;
    std::cout << "M√©moire totale: " << totalMemory << " GB" << std::endl;
    std::cout << "M√©moire disponible: " << availableMemory << " GB" << std::endl;
    
    std::cout << "\n‚ú® Simulation termin√©e avec succ√®s!" << std::endl;
    
    return 0;
}

/*
POINTS CL√âS DE CETTE IMPL√âMENTATION :

1. **Encapsulation**: Les attributs sont priv√©s, acc√®s via getters/setters
2. **Constructeur avec initialisation**: Utilisation de la liste d'initialisation
3. **Const correctness**: Les m√©thodes qui ne modifient pas l'objet sont const
4. **STL**: Utilisation de std::vector pour stocker les GPUs
5. **Fonctions utilitaires**: Code modulaire et r√©utilisable
6. **Gestion d'erreurs**: V√©rification des conditions avant allocation
7. **Interface utilisateur**: Affichage format√© et informatif

AM√âLIORATIONS POSSIBLES :
- Ajouter la gestion d'exceptions
- Impl√©menter un syst√®me de r√©servation temporaire
- Ajouter des m√©triques de performance
- Sauvegarder l'√©tat du cluster dans un fichier
- Ajouter des logs d'activit√©
- Impl√©menter un syst√®me de priorit√©s pour les jobs
*/